faithfulness (or fidelity) of surrogate and model assumes same decision process
  - https://arxiv.org/pdf/2004.03685.pdf

local fidelity with same weights used to train the surrogate model
  - as the surrogate only aims to be interpreting this region well

(in)fidelity paper:
  - https://arxiv.org/pdf/1901.09392.pdf




Research ideas:
show that local weighting of lime helps local fidelity
show class balanced helps class balanced fidelity
show other cost sensitive trained models where you need to do other things for lime (e.g. for boundary adjust we find that you shoudln't do cost sensitive lime for some reason?)





Papers:

Class imbalance paper that uses LIME to give explanation: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010144
LIME after using over sampling 1: https://ieeexplore.ieee.org/abstract/document/9720806
LIMe after using over sampling 2: https://ieeexplore.ieee.org/abstract/document/9906532




Potential datasets:
Stroke https://www.kaggle.com/datasets/shashwatwork/cerebral-stroke-predictionimbalaced-dataset




Methods:
oversampling: K-Means SMOTE (Synthetic Minority Oversampling Technique)







Less relevant papers:
Interpretable ML for imbalance data: https://arxiv.org/pdf/2212.07743.pdf
Revisiting Example Dependent Cost-Sensitive Learning with Decision Trees: https://ieeexplore.ieee.org/document/6751133
Ensemble of Example-Dependent Cost-Sensitive Decision Trees: https://arxiv.org/pdf/1505.04637.pdf


Even less relevent but still interesting:
Towards Robust Interpretability with Self-Explaining Neural Networks: https://proceedings.neurips.cc/paper/2018/file/3e9f0fc9b2f89e043bc6233994dfcf76-Paper.pdf
